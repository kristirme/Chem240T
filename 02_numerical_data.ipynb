{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5122e45e-9575-4347-b47a-1e4a38645a65",
   "metadata": {},
   "source": [
    "# Working with Data \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Overview</h2>\n",
    "\n",
    "Questions:\n",
    "\n",
    "* How do I work with numerical data presented in tables?\n",
    "* What is NumPy? What is pandas?\n",
    "* What is an array? What is a dataframe?\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* Use functions in `numpy` to read in tabular data.\n",
    "* Take 2D slices of data in numpy arrays.\n",
    "* Use 2D slices to work with particular rows or columns of data.\n",
    "* Use the `range()` function in `for` loops.\n",
    "* Use `numpy` functions to analyze data.\n",
    "* Use `pandas` dataframes for more complex data.\n",
    "\n",
    "</div>\n",
    "\n",
    "Most scientists work with a lot of numerical data. In this module we will focus on reading in and analyzing numerical data, visualizing the data, and working with arrays.\n",
    "\n",
    "## Reading in Tabular Data\n",
    "\n",
    "In our last module, we used the `readlines()` function to read in a complex output file. In theory, you could always use the `readlines()` function, and then use the data parsing tools we learned in the previous module to format the data as you needed. But sometimes there are other ways that make more sense, particularly if the data is (1) all or mostly one type of data (for example, all numbers) and/or (2) formatted in a table. Frequently, a table will be mostly numbers, but have column or row labels.\n",
    "\n",
    "A common table format is the CSV file or comma separated values. This is exactly what it sounds like. Data is presented in rows, with each value separated by a comma. If you have data in a spreadsheet program that you need to import into a python code, you can save the data as a .csv file to read it in.\n",
    "\n",
    "In this example, we have a CSV file that contains data from a molecular dynamics trajectory. We have a 20 ns simulation that used a 2 fs timestep. The data was saved to the trajectory file every 1000 steps, so our file has 10,000 timesteps. At each timestep, we are interested in the distance between particular atoms. These trajectories were generated with the AMBER molecular dynamics program and the distances were measured with the python program MDAnalysis. The table of atomic distances was saved as a CVS file called “distance_data_headers.csv”. This file is included in the data folder. Open the file on ChemCompute to determine its structure.\n",
    "\n",
    "In analyzing tabular data, we often need to perform the same types of calculations (averaging, calculating the minimum or maximum of the data set), so we are going to use a python library, in this case, one that contains lots of functions to perform math operations. This library is called `numpy`. The `numpy` library has several functions available to read in tabular data. One of these functions is the `genfromtxt()` function. We will use the `help()` function to learn more about `genfromtxt()` and how it works. The help function can be used for nearly any built in python function and many libraries. When `numpy` is imported, it is often shortened to `np` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be0b9884-d2ee-448b-aa25-91dcd5f1f0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function genfromtxt in module numpy:\n",
      "\n",
      "genfromtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, skip_header=0, skip_footer=0, converters=None, missing_values=None, filling_values=None, usecols=None, names=None, excludelist=None, deletechars=\" !#$%&'()*+,-./:;<=>?@[\\\\]^{|}~\", replace_space='_', autostrip=False, case_sensitive=True, defaultfmt='f%i', unpack=None, usemask=False, loose=True, invalid_raise=True, max_rows=None, encoding='bytes', *, ndmin=0, like=None)\n",
      "    Load data from a text file, with missing values handled as specified.\n",
      "    \n",
      "    Each line past the first `skip_header` lines is split at the `delimiter`\n",
      "    character, and characters following the `comments` character are discarded.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : file, str, pathlib.Path, list of str, generator\n",
      "        File, filename, list, or generator to read.  If the filename\n",
      "        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
      "        that generators must return bytes or strings. The strings\n",
      "        in a list or produced by a generator are treated as lines.\n",
      "    dtype : dtype, optional\n",
      "        Data type of the resulting array.\n",
      "        If None, the dtypes will be determined by the contents of each\n",
      "        column, individually.\n",
      "    comments : str, optional\n",
      "        The character used to indicate the start of a comment.\n",
      "        All the characters occurring on a line after a comment are discarded.\n",
      "    delimiter : str, int, or sequence, optional\n",
      "        The string used to separate values.  By default, any consecutive\n",
      "        whitespaces act as delimiter.  An integer or sequence of integers\n",
      "        can also be provided as width(s) of each field.\n",
      "    skiprows : int, optional\n",
      "        `skiprows` was removed in numpy 1.10. Please use `skip_header` instead.\n",
      "    skip_header : int, optional\n",
      "        The number of lines to skip at the beginning of the file.\n",
      "    skip_footer : int, optional\n",
      "        The number of lines to skip at the end of the file.\n",
      "    converters : variable, optional\n",
      "        The set of functions that convert the data of a column to a value.\n",
      "        The converters can also be used to provide a default value\n",
      "        for missing data: ``converters = {3: lambda s: float(s or 0)}``.\n",
      "    missing : variable, optional\n",
      "        `missing` was removed in numpy 1.10. Please use `missing_values`\n",
      "        instead.\n",
      "    missing_values : variable, optional\n",
      "        The set of strings corresponding to missing data.\n",
      "    filling_values : variable, optional\n",
      "        The set of values to be used as default when the data are missing.\n",
      "    usecols : sequence, optional\n",
      "        Which columns to read, with 0 being the first.  For example,\n",
      "        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.\n",
      "    names : {None, True, str, sequence}, optional\n",
      "        If `names` is True, the field names are read from the first line after\n",
      "        the first `skip_header` lines. This line can optionally be preceded\n",
      "        by a comment delimiter. If `names` is a sequence or a single-string of\n",
      "        comma-separated names, the names will be used to define the field names\n",
      "        in a structured dtype. If `names` is None, the names of the dtype\n",
      "        fields will be used, if any.\n",
      "    excludelist : sequence, optional\n",
      "        A list of names to exclude. This list is appended to the default list\n",
      "        ['return','file','print']. Excluded names are appended with an\n",
      "        underscore: for example, `file` would become `file_`.\n",
      "    deletechars : str, optional\n",
      "        A string combining invalid characters that must be deleted from the\n",
      "        names.\n",
      "    defaultfmt : str, optional\n",
      "        A format used to define default field names, such as \"f%i\" or \"f_%02i\".\n",
      "    autostrip : bool, optional\n",
      "        Whether to automatically strip white spaces from the variables.\n",
      "    replace_space : char, optional\n",
      "        Character(s) used in replacement of white spaces in the variable\n",
      "        names. By default, use a '_'.\n",
      "    case_sensitive : {True, False, 'upper', 'lower'}, optional\n",
      "        If True, field names are case sensitive.\n",
      "        If False or 'upper', field names are converted to upper case.\n",
      "        If 'lower', field names are converted to lower case.\n",
      "    unpack : bool, optional\n",
      "        If True, the returned array is transposed, so that arguments may be\n",
      "        unpacked using ``x, y, z = genfromtxt(...)``.  When used with a\n",
      "        structured data-type, arrays are returned for each field.\n",
      "        Default is False.\n",
      "    usemask : bool, optional\n",
      "        If True, return a masked array.\n",
      "        If False, return a regular array.\n",
      "    loose : bool, optional\n",
      "        If True, do not raise errors for invalid values.\n",
      "    invalid_raise : bool, optional\n",
      "        If True, an exception is raised if an inconsistency is detected in the\n",
      "        number of columns.\n",
      "        If False, a warning is emitted and the offending lines are skipped.\n",
      "    max_rows : int,  optional\n",
      "        The maximum number of rows to read. Must not be used with skip_footer\n",
      "        at the same time.  If given, the value must be at least 1. Default is\n",
      "        to read the entire file.\n",
      "    \n",
      "        .. versionadded:: 1.10.0\n",
      "    encoding : str, optional\n",
      "        Encoding used to decode the inputfile. Does not apply when `fname` is\n",
      "        a file object.  The special value 'bytes' enables backward compatibility\n",
      "        workarounds that ensure that you receive byte arrays when possible\n",
      "        and passes latin1 encoded strings to converters. Override this value to\n",
      "        receive unicode arrays and pass strings as input to converters.  If set\n",
      "        to None the system default is used. The default value is 'bytes'.\n",
      "    \n",
      "        .. versionadded:: 1.14.0\n",
      "    ndmin : int, optional\n",
      "        Same parameter as `loadtxt`\n",
      "    \n",
      "        .. versionadded:: 1.23.0\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "    \n",
      "        .. versionadded:: 1.20.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Data read from the text file. If `usemask` is True, this is a\n",
      "        masked array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.loadtxt : equivalent function when no data is missing.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    * When spaces are used as delimiters, or when no delimiter has been given\n",
      "      as input, there should not be any missing data between two fields.\n",
      "    * When the variables are named (either by a flexible dtype or with `names`),\n",
      "      there must not be any header in the file (else a ValueError\n",
      "      exception is raised).\n",
      "    * Individual values are not stripped of spaces by default.\n",
      "      When using a custom converter, make sure the function does remove spaces.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] NumPy User Guide, section `I/O with NumPy\n",
      "           <https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from io import StringIO\n",
      "    >>> import numpy as np\n",
      "    \n",
      "    Comma delimited file with mixed dtype\n",
      "    \n",
      "    >>> s = StringIO(u\"1,1.3,abcde\")\n",
      "    >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),\n",
      "    ... ('mystring','S5')], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "    \n",
      "    Using dtype = None\n",
      "    \n",
      "    >>> _ = s.seek(0) # needed for StringIO example only\n",
      "    >>> data = np.genfromtxt(s, dtype=None,\n",
      "    ... names = ['myint','myfloat','mystring'], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "    \n",
      "    Specifying dtype and names\n",
      "    \n",
      "    >>> _ = s.seek(0)\n",
      "    >>> data = np.genfromtxt(s, dtype=\"i8,f8,S5\",\n",
      "    ... names=['myint','myfloat','mystring'], delimiter=\",\")\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n",
      "    \n",
      "    An example with fixed-width columns\n",
      "    \n",
      "    >>> s = StringIO(u\"11.3abcde\")\n",
      "    >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],\n",
      "    ...     delimiter=[1,3,5])\n",
      "    >>> data\n",
      "    array((1, 1.3, b'abcde'),\n",
      "          dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])\n",
      "    \n",
      "    An example to show comments\n",
      "    \n",
      "    >>> f = StringIO('''\n",
      "    ... text,# of chars\n",
      "    ... hello world,11\n",
      "    ... numpy,5''')\n",
      "    >>> np.genfromtxt(f, dtype='S12,S12', delimiter=',')\n",
      "    array([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')],\n",
      "      dtype=[('f0', 'S12'), ('f1', 'S12')])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np      #commonly shortened name for library\n",
    "help(np.genfromtxt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a5176-da8c-4ed8-839d-d1f5b127aad1",
   "metadata": {},
   "source": [
    "The help menu shows us all the options we can use with this function. The first input `fname` is the filename we are reading in. We must put a values for this option because it does not have a default value. All the other options have a default value that is shown after the = sign. We only need to specify these options if we don’t want to use the default value. For example, in our file, all the values were not numbers so we don’t want to use the datatype `float`, we want to use something else. If you have mixed datatypes, like we do here, we want to use `'unicode'`. In our file, our values are separated by commas; we indicate that with `delimiter=','`.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<strong>Should you skip the headers?</strong>\n",
    "\n",
    "If you read the help information carefully, you may notice the `skip_header` option, where you can specify a number of lines to skip at the beginning of the file. If we did this, then our values would all be numbers and we could use dtype=’float’, which is the default. In this example, we are not going to do that because we might want to use the headers later to label things, but keep this option in mind because you might want to use it in a later project.\n",
    "\n",
    "</div>  \n",
    "\n",
    "Now we have have our plan, we are ready to import our data with `genfromtxt()`.\n",
    "\n",
    "First, we have to get the path to our file. Remember from previous lessons that we use the `os.path` module to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "658c9abb-060e-4a1f-af01-db80189259cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Frame' 'THR4_ATP' 'THR4_ASP' 'TYR6_ATP' 'TYR6_ASP']\n",
      " ['1' '8.9542' '5.8024' '11.5478' '9.9557']\n",
      " ['2' '8.6181' '6.0942' '13.9594' '11.6945']\n",
      " ...\n",
      " ['9998' '8.6625' '7.7306' '9.5469' '10.3063']\n",
      " ['9999' '9.2456' '7.8886' '9.8151' '10.7564']\n",
      " ['10000' '8.8135' '7.917' '9.9517' '10.7848']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "distance_file = os.path.join('data', 'distance_data_headers.csv')\n",
    "\n",
    "distances = np.genfromtxt(distance_file, delimiter=',', dtype='unicode')\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288a376-ffc4-4df3-91aa-af41142b5a5d",
   "metadata": {},
   "source": [
    "The output of this function is a list of lists; that is, each row is a entry in our list, but each row is itself a list of values. We can see that the first row is our column headings and all the other rows contain numerical data.\n",
    "\n",
    "If we were to read this in with the readlines() function, we would have to split each line of the file, use the `append` function to make a new list for each row, and THEN put all those lists together into a list of lists. Using the appropriate `numpy` function makes our life much easier.\n",
    "\n",
    "## Manipulating Tabular Data\n",
    "\n",
    "Now we can clearly see that our first line of data is headings for our columns, and will need to be stored as strings, whereas all the rest of the data is numerical and will need to be stored as floats. Let’s take a slice of the data that is just the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ffbbf7-7282-426a-8bec-14a4432eab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frame' 'THR4_ATP' 'THR4_ASP' 'TYR6_ATP' 'TYR6_ASP']\n"
     ]
    }
   ],
   "source": [
    "headers = distances[0]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa119a8-b253-4464-a4e1-0bcd885e33c6",
   "metadata": {},
   "source": [
    "Now take a slice of the data that contains all the numerical values. Replace the '0' with the appropriate range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7024fd32-d717-41e3-92a8-4af707c32cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '8.9542' '5.8024' '11.5478' '9.9557']\n",
      " ['2' '8.6181' '6.0942' '13.9594' '11.6945']\n",
      " ['3' '9.0066' '6.0637' '13.0924' '11.3043']\n",
      " ...\n",
      " ['9998' '8.6625' '7.7306' '9.5469' '10.3063']\n",
      " ['9999' '9.2456' '7.8886' '9.8151' '10.7564']\n",
      " ['10000' '8.8135' '7.917' '9.9517' '10.7848']]\n"
     ]
    }
   ],
   "source": [
    "data = distances[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004164d-82c3-42e9-aac5-b29508e0aa2f",
   "metadata": {},
   "source": [
    "Even though we now have a list of lists that is just the numbers, the numbers are all still strings. We know this because (1) we read them all in as unicode and (2) if we look at the output of the print statement, we can see that each number is enclosed in single quotes, indicating that it is a string. We need to recast these values as floats. The `numpy` library has a built-in function to accomplish this. In this case, keeping a variable with all the same information as strings is not useful to us, so this is a case where we are going to overwrite our variable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4727af3a-0e7d-4d4d-83e3-07de2dcea508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000e+00 8.95420e+00 5.80240e+00 1.15478e+01 9.95570e+00]\n",
      " [2.00000e+00 8.61810e+00 6.09420e+00 1.39594e+01 1.16945e+01]\n",
      " [3.00000e+00 9.00660e+00 6.06370e+00 1.30924e+01 1.13043e+01]\n",
      " ...\n",
      " [9.99800e+03 8.66250e+00 7.73060e+00 9.54690e+00 1.03063e+01]\n",
      " [9.99900e+03 9.24560e+00 7.88860e+00 9.81510e+00 1.07564e+01]\n",
      " [1.00000e+04 8.81350e+00 7.91700e+00 9.95170e+00 1.07848e+01]]\n"
     ]
    }
   ],
   "source": [
    "data = data.astype(float)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dbbe5-6c22-45bd-8531-97579303c124",
   "metadata": {},
   "source": [
    "We already learned how to address a particular element of a list and how to take a slice of a list to create a new list. Now that we have an array, we now need two indices to address a particular element of the array. The notation to address an element of the array is always\n",
    "\n",
    "```python\n",
    " array_name[row,column]\n",
    "\n",
    "```\n",
    "\n",
    "Before running the following cells, predict the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe932f0-0ae1-4cf8-a987-2927ca2970d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9542\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(data[0,1])\n",
    "print(data[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e1e4e-5604-4b3d-9ebd-128f3c387f20",
   "metadata": {},
   "source": [
    "You can also take two-dimensional slices of an array where you specify a range of rows and a range of columns for the slice. For example, sometimes it is easier to work with a small subset of our data for testing rather than the full data set. This command takes a slice that includes only the first ten rows and the first three columns of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ded3feb6-78ef-4fd1-aa3b-b50160c75386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      8.9542  5.8024]\n",
      " [ 2.      8.6181  6.0942]\n",
      " [ 3.      9.0066  6.0637]\n",
      " [ 4.      9.2002  6.0227]\n",
      " [ 5.      9.1294  5.9365]\n",
      " [ 6.      9.0462  6.2553]\n",
      " [ 7.      8.8657  5.9186]\n",
      " [ 8.      9.3256  6.2351]\n",
      " [ 9.      9.4184  6.1993]\n",
      " [10.      9.06    6.0478]]\n"
     ]
    }
   ],
   "source": [
    "small_data = data[0:10,0:3]\n",
    "print(small_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54acd268-ad81-484c-9c31-d543f832f011",
   "metadata": {},
   "source": [
    "Remember that counting starts at zero, so 0:10 means start at row zero and include all rows, up to but not including 10. Just as with the one-dimensional list slices, if you don’t include a number before the `:` the slice automatically starts with `list_name[0]`. If you don’t include a number after the `:` the slice goes to the end of the list. Therefore, if you don’t include either, a `:` means *every row* or *every column\n",
    "\n",
    "Before running the following cells, predict the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8705e6a7-15bc-482f-9494-3cc2f386b1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.     9.0462 6.2553]\n",
      "[[8.9542 5.8024]\n",
      " [8.6181 6.0942]\n",
      " [9.0066 6.0637]\n",
      " [9.2002 6.0227]\n",
      " [9.1294 5.9365]\n",
      " [9.0462 6.2553]\n",
      " [8.8657 5.9186]\n",
      " [9.3256 6.2351]\n",
      " [9.4184 6.1993]\n",
      " [9.06   6.0478]]\n"
     ]
    }
   ],
   "source": [
    "print(small_data[5,:])\n",
    "print(small_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10a860-6edf-4533-adfc-b04375f34bc7",
   "metadata": {},
   "source": [
    "** Analyzing Tabular Data\n",
    "\n",
    "The `numpy` library has numerous built-in functions. For example, to calculate the average (mean) of a data set, the syntax is\n",
    "```python\n",
    "data_average = numpy.mean(data_set)\n",
    "```\n",
    "\n",
    "Let’s say we want to calculate the average distance for a particular measurement over the whole simulation. We want to calculate the average of one of the columns. We can take a slice of our data array that is just one column. Then we can find the average of that column. It doesn’t make sense to average the frame numbers, so let’s do the THR4_ATP column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd3ca86-2c39-4745-8ed8-31e3a0270b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.876950930000001\n"
     ]
    }
   ],
   "source": [
    "thr4_atp = data[:,1]  # Every row, just the THR4_ATP column\n",
    "avg_thr4_atp = np.mean(thr4_atp)\n",
    "print(avg_thr4_atp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6c102-3e75-4b45-94c0-aff52e843378",
   "metadata": {},
   "source": [
    "This is correct, but now we would like to calculate the average of every column. This seems like a job for a `for` loop, but unlike last time, we don’t want to count over a particular list and do something for every item, we want to do something a particular number of times. Basically, we want to take that `1` and let it be every number, up to the number of columns. This is a task for the `range()` function. The general syntax is\n",
    "```python\n",
    "range(start, end)\n",
    "\n",
    "```\n",
    "and we can use `range()` in a `for` loop.\n",
    "\n",
    "In our example, the “end” value needs to be the number of columns of data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<strong>Check your understanding</strong>\n",
    "    \n",
    "Complete the code below to determine the number of columns in our data set using the `len` function. Save this value as a variable called num_columns.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55628cd9-dca9-4919-86ee-859e3728c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "num_columns = \n",
    "print(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd6f06-16b0-4444-b172-cbc543798e49",
   "metadata": {},
   "source": [
    "Now that we know the number of columns, we can use the `range()` function to set up our `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb78f1dd-d2b0-4884-b420-576c703271a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THR4_ATP : 10.876950930000001\n",
      "THR4_ASP : 7.342344959999999\n",
      "TYR6_ATP : 11.209791329999998\n",
      "TYR6_ASP : 10.9934435\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,num_columns):\n",
    "    column = data[:,i]\n",
    "    avg_col = np.mean(column)\n",
    "    print(F'{headers[i]} : {avg_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff0c4c-d741-4e38-994e-19ca7d119fc3",
   "metadata": {},
   "source": [
    "## NumPy Arrays vs. Python Lists\n",
    "\n",
    "When using `numpy` to import your data a special data type called a numpy array is created. This is similar to the built in list functions in python that were used in the previous activities, but numpy arrays take up less space, are faster, and have more mathematical operations associated with them. All elements in a numpy array must be the same type.\n",
    "\n",
    "There are also differences in how lists and numpy arrays behave. Let’s look at some of these. We will start with reading in some data from an xyz file. The following block will read a file called water.xyz and saving two numpy arrays - one called coordinates with the molecular `coordinates`, and another called `symbols` with the element symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b66630a-35f6-4ea9-b208-9274b8e02bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'H1' 'H2']\n",
      "[[ 0.       -0.007156  0.965491]\n",
      " [-0.        0.001486 -0.003471]\n",
      " [ 0.        0.931026  1.207929]]\n"
     ]
    }
   ],
   "source": [
    "file_location = os.path.join('data', 'water.xyz')\n",
    "xyz_file = np.genfromtxt(file_location, skip_header=2, dtype='unicode')\n",
    "symbols = xyz_file[:,0]\n",
    "coordinates = (xyz_file[:,1:])\n",
    "coordinates = coordinates.astype(float)\n",
    "\n",
    "print(symbols)\n",
    "print(coordinates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8acb1-605e-4b74-a06d-70586344c140",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<strong>Check your understanding</strong>\n",
    "    \n",
    "Slice the `coordinates` array to create a new array called `oxygen_coord` which has the x, y, and z coordinate for the oxygen atom.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f5f283-a716-494a-8d4e-ee8fbbdcdbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeaf5a30-c5f7-4f23-ab89-fea79d90d4d8",
   "metadata": {},
   "source": [
    "Now that we have the oxygen coordinate, let’s imagine we wanted to do something to it. Let’s imagine that we wanted to translate the position of the oxygen atom. We want to translate it 0.1 units in the x direction and -0.1 units in the y direction.\n",
    "\n",
    "If we were writing for loops like we did before, we might do this by defining a translation vector and using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adddc4dc-f530-4d38-9311-64728d79ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.107156, 0.965491]\n"
     ]
    }
   ],
   "source": [
    "translation_vector = [0.1, -0.1, 0]\n",
    "\n",
    "oxygen_coord_new = []\n",
    "\n",
    "for dim in range(3):\n",
    "    new_position = oxygen_coord[dim] + translation_vector[dim]\n",
    "    oxygen_coord_new.append(new_position)\n",
    "\n",
    "print(oxygen_coord_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bcabf-138c-4c83-aad3-12b6b641b95a",
   "metadata": {},
   "source": [
    "However, since `oxygen_coord` is a numpy array, we could have done this differently. One way numpy arrays and lists are different is that you can easily perform element-wise operations on numpy arrays without loops. You can make your code much faster if you use numpy element-by-element operations instead of loops.\n",
    "\n",
    "Numpy is smart. If two arrays (or a list and an array), it will guess that you want to do element-wise addition. In the `for` loop we just wrote, we actually wanted an answer that looked like `[x1+x2, y1+y2, z1+z2]` where [x1, x2, x3] was `oxygen_coord` and [y1, y2, y3] was `translation_vector`. Using the power of numpy arrays, we could have instead written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f2880c-e036-49c3-9667-eaeefb156a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1      -0.107156  0.965491]\n"
     ]
    }
   ],
   "source": [
    "oxygen_coord_new = oxygen_coord + translation_vector\n",
    "print(oxygen_coord_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d355d-d258-4188-ab67-bc1098e14409",
   "metadata": {},
   "source": [
    "Numpy was smart - it looked at the shape of both of these variables, saw they were the same shape, and assumed we wanted to do element-wise operation. You could have also subtracted, multiplied, or divided these, and it would have performed element-wise operations.\n",
    "\n",
    "Note, that this only worked because `oxygen_coord` was a `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "814979a7-50fb-4ad2-bb66-42b9ddcbbcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(oxygen_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fc46d-a58f-427c-a891-f8dee2a0b059",
   "metadata": {},
   "source": [
    "What happens if we try this with a list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0173a595-1f37-4c11-9725-be00fb6e6666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxygen_list = list(oxygen_coord)\n",
    "type(oxygen_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9286ccc3-d8b7-4d91-89d0-b39c4f01b320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, -0.007156, 0.965491, 0.1, -0.1, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxygen_list + translation_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e22180-f938-4100-9357-9bea57da28eb",
   "metadata": {},
   "source": [
    "This process is called concatenation, where the two lists are just joined together. As a note, if you wanted to concatenate the two where `oxygen_coordinate` was a numpy array, you could have done so with the `np.concatenate` function.\n",
    "\n",
    "You can add two numpy arrays together, multiply arrays by scalars, or do element-wise multiplcation of arrays.\n",
    "\n",
    "For example, you can multiply two numpy arrays to get their element-wise product. This means that given two vectors `a = np.array([a0, a1, a2])` and `b = np.array([b0, b1, b2])`, `a * b = [a0*b0, a1*a1, a2*b2]`.\n",
    "\n",
    "In contrast, if `a`and `b` were lists, you would get an error.\n",
    "\n",
    "To check yourself, before running the follow cells, predict the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ce416f-8052-4bf1-a934-008b2c85c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0]\n",
      "[3 4 5]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([2, 1, 0])\n",
    "a2 = np.array([1, 3, 5])\n",
    "\n",
    "print(a1 * a2)\n",
    "print(a1 + a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3686521b-9ad9-4c87-b372-80e4aef42858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 1, 3, 5]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m a2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(a1 \u001b[38;5;241m+\u001b[39m a2)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "a1 = [2, 1, 0]\n",
    "a2 = [1, 3, 5]\n",
    "\n",
    "print(a1 + a2)\n",
    "print(a1 * a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad473992-432d-47d0-b78d-52c77d9e22ca",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Another special thing about numpy is something called **broadcasting**. Broadcasting occurs when you attempt mathematical operations on arrays that have different shapes. If possible, the smaller array is “broadcast” across the larger array.\n",
    "\n",
    "Let’s think about what would happen if we wanted to move every atom in our water molecule by our translation vector.\n",
    "\n",
    "If you were working with Python lists, or you didn’t know about the features of numpy arrays, you might try to do this with a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76d3ad12-fdf0-4ac3-b485-7e6260895f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1, -0.107156, 0.965491], [0.1, -0.098514, -0.003471], [0.1, 0.831026, 1.207929]]\n"
     ]
    }
   ],
   "source": [
    "new_coordinates = []\n",
    "\n",
    "for atom in coordinates:\n",
    "    new_x = atom[0] + translation_vector[0]\n",
    "    new_y = atom[1] + translation_vector[1]\n",
    "    new_z = atom[2] + translation_vector[2]\n",
    "    \n",
    "    new_coordinates.append([new_x, new_y, new_z])\n",
    "    \n",
    "print(new_coordinates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55b21a-21f8-4a79-a609-39b33dfb73f0",
   "metadata": {},
   "source": [
    "Broadcasting in `numpy` allows us to achieve that with one command, rather than a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "436d3efc-1f82-46a5-ab31-8b95daee8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1      -0.107156  0.965491]\n",
      " [ 0.1      -0.098514 -0.003471]\n",
      " [ 0.1       0.831026  1.207929]]\n"
     ]
    }
   ],
   "source": [
    "new_coordinates = coordinates + translation_vector\n",
    "\n",
    "print(new_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73ebef-7265-411f-a658-bf8b39e10b51",
   "metadata": {},
   "source": [
    "For this to work, we have to have two arrays that have a matching dimension. You can see the shape of an array using the function `np.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cb3fb13-a264-4c03-81cd-dc8fbb7b210c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a56dab77-1dc4-46a0-b7bb-48ecaf22ba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(translation_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddaff4-37ab-4db7-bd7f-0d0bb3ceb1dc",
   "metadata": {},
   "source": [
    "When you typed, `coordinates + translation_vector`, numpy looked at the shapes of both arrays to figure out if they were compatible.\n",
    "\n",
    "It starts with the dimensions to the right, so when it saw to matching 3’s it assumed you wanted to do element-wise operation this way, and stretched or ‘broadcast’ the smaller array to match the larger one.\n",
    "\n",
    "## Logical comparisons\n",
    "\n",
    "We can also do logical comparisons on whole arrays. For example, to find out if values in the array are greater than 0, we can write the following print statement, which will print either `True` or `False` for each array elelement depending on whehter it is greater than 0 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33a8f1ea-2fa6-4457-a317-daeb315e73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False  True]\n",
      " [False  True False]\n",
      " [False  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(coordinates > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca498552-5f5f-45dc-afe2-5d2b3df0abe3",
   "metadata": {},
   "source": [
    "To get every value in the array that is greater than 0, we can use this as a list of indices we want, or a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f02bd12-0091-4175-bdf1-2b57de1692aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.965491 0.001486 0.931026 1.207929]\n"
     ]
    }
   ],
   "source": [
    "greater_than_0_values = coordinates[coordinates>0]\n",
    "print(greater_than_0_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357d2e5-ef96-42f2-aa2f-f1d7ffef8cb3",
   "metadata": {},
   "source": [
    "## Array Axes\n",
    "\n",
    "Imagine we wanted to calculate the geometric center of our molecule. To do this, we would need to get the average x coordinate, the average y coordinate, and the average z coordinate.\n",
    "\n",
    "A `numpy` array can be thought of like a coordinates system. Axis 0 runs along the ROWS, while axis 1 runs along the COLUMNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a01c3b32-5e8a-450a-a6b4-192c60822247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      , -0.007156,  0.965491],\n",
       "       [-0.      ,  0.001486, -0.003471],\n",
       "       [ 0.      ,  0.931026,  1.207929]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "099d2e48-e5a2-4e84-9529-7270350e8251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.308452   0.72331633]\n"
     ]
    }
   ],
   "source": [
    "center = np.mean(coordinates, axis=0) # mean of each column\n",
    "print(center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee346fc6-79e7-4822-8fee-69dc95e80a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.19445000e-01 -6.61666667e-04  7.12985000e-01]\n"
     ]
    }
   ],
   "source": [
    "center = np.mean(coordinates, axis=1) # mean of each row \n",
    "print(center)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea69e0-dfc8-4b5f-a393-7b1b0154562d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<strong>Key Points</strong>\n",
    "\n",
    "\n",
    "* NumPy arrays which are the same size use element-wise operations when added or subtracted\n",
    "* NumPy uses something called broadcasting for arrays which are not the same size to allow arrays to be added or multiplied.\n",
    "* NumPy has extensive documentation online - you should check this out if you need to do a computation.\n",
    "\n",
    "\n",
    "</div>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccbd596-f46d-4468-820f-18f1f393f99b",
   "metadata": {},
   "source": [
    "## What is pandas?\n",
    "\n",
    "Pandas is another Python package which is very popular for data analysis. The key feature of pandas is the `dataframe`. Here we will discuss dataframes and some basic analysis.\n",
    "\n",
    "NumPy is useful when you are working with data that is all numeric. Pandas, however, is capable of handling data of lots of different types. It is designed to make working with “relational” or “labeled” data easy and intuitive. Central to the `pandas` package are the special data structures called pandas Series and DataFrames. Pandas dataframes are 2 dimensional and tabular, and is particularly suited to data which is heterogenous and in columns, like an Excel spreadsheet. In fact, there are even functions which allow you to read data directly from excel spreadsheets (more on this later).\n",
    "\n",
    "Pandas is built to closely work with NumPy. Many functions which work on NumPy arrays will also work on Pandas DataFrames.\n",
    "\n",
    "First we need to load `pandas` it is often abbreviated as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dbd42cf-c13f-4181-bc15-d4b9c3083fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be295b6f-25ce-4ef2-af4a-b1bcde7994bd",
   "metadata": {},
   "source": [
    "For this section, we will be working with a data set that contains information about the elements in the periodic table.The data is a csv (comma separated value) file from PubChem. \n",
    "\n",
    "Once you have the file downloaded and saved in your directory, we will load it into pandas. This file is a csv (comma separated value) file, so we will load it using the pd.read_csv command."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
